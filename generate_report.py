#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
åŸºäºAPIå“åº”ç”Ÿæˆèƒ°è…ºç™Œä¸´åºŠè¯•éªŒæŠ¥å‘Š
é›†æˆAPIè°ƒç”¨å’Œæ—¥æœŸè¿‡æ»¤é€»è¾‘
"""

import json
import requests
import logging
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any
import time
import os
from urllib.parse import urlencode, quote_plus

def setup_logging():
    """è®¾ç½®æ—¥å¿—é…ç½®"""
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler('pancreatic_trials.log', encoding='utf-8'),
            logging.StreamHandler()
        ]
    )
    return logging.getLogger(__name__)

def search_studies(query: str, page_size: int = 50, phases: List[str] = None, status: List[str] = None, first_post_date: str = None, location: str = None, logger=None) -> Dict[str, Any]:
    """
    æœç´¢ä¸´åºŠè¯•éªŒ
    
    Args:
        query: æœç´¢æŸ¥è¯¢å­—ç¬¦ä¸²
        page_size: æ¯é¡µè¿”å›çš„ç»“æœæ•°é‡
        phases: è¯•éªŒé˜¶æ®µåˆ—è¡¨ ['PHASE1', 'PHASE2', 'PHASE3', 'PHASE4', 'EARLY_PHASE1']
        status: è¯•éªŒçŠ¶æ€åˆ—è¡¨ ['RECRUITING', 'NOT_YET_RECRUITING', 'ACTIVE_NOT_RECRUITING']
        first_post_date: é¦–æ¬¡å‘å¸ƒæ—¥æœŸè¿‡æ»¤ï¼Œæ ¼å¼å¦‚'2025-01-01'
        location: åœ°ç†ä½ç½®è¿‡æ»¤ï¼Œå¦‚'china'
        
    Returns:
        APIå“åº”çš„JSONæ•°æ®
    """
    base_url = "https://beta-ut.clinicaltrials.gov/api/v2/studies"
    
    # æ„å»ºåŸºç¡€å‚æ•°
    params = {
        'format': 'json',
        'markupFormat': 'markdown',
        'query.cond': query,
        'countTotal': 'true',
        'pageSize': page_size
    }
    
    # æ·»åŠ è¯•éªŒçŠ¶æ€è¿‡æ»¤
    if status:
        params['filter.overallStatus'] = ','.join(status)
    else:
        params['filter.overallStatus'] = 'RECRUITING'
    
    # æ·»åŠ å¼€å§‹æ—¥æœŸè¿‡æ»¤
    if first_post_date:
        year = first_post_date.split('-')[0]  # æå–å¹´ä»½
        params['postFilter.advanced'] = f'AREA[StartDate]{year}'
    
    # æ·»åŠ åœ°ç†ä½ç½®è¿‡æ»¤
    if location:
        params['query.locn'] = location
    
    # æ·»åŠ è¯•éªŒé˜¶æ®µè¿‡æ»¤
    if phases:
        phase_numbers = []
        for phase in phases:
            if phase == '0' or phase == 'EARLY_PHASE1':
                phase_numbers.append('0')
            elif phase == '1' or phase == 'PHASE1':
                phase_numbers.append('1')
            elif phase == '2' or phase == 'PHASE2':
                phase_numbers.append('2')
            elif phase == '3' or phase == 'PHASE3':
                phase_numbers.append('3')
            elif phase == '4' or phase == 'PHASE4':
                phase_numbers.append('4')
        if phase_numbers:
            phase_filter = '+'.join(sorted(set(phase_numbers), reverse=True))
            params['aggFilters'] = f'status:rec,phase:{phase_filter}'
    else:
        params['aggFilters'] = 'status:rec,phase:4+3+2+1'
    
    try:
        if logger:
            logger.info(f"æ­£åœ¨æŸ¥è¯¢: {query}")
        
        # æ„å»ºURL
        agg_filters = params.pop('aggFilters', None)
        post_filter = params.pop('postFilter.advanced', None)
        base_params = urlencode(params, quote_via=quote_plus)
        
        full_url = f"{base_url}?{base_params}"
        
        if post_filter:
            encoded_post_filter = post_filter.replace('[', '%5B').replace(']', '%5D')
            full_url += f"&postFilter.advanced={encoded_post_filter}"
        
        if agg_filters:
            full_url += f"&aggFilters={agg_filters.replace(':', '%3A')}"
        
        if logger:
            logger.info(f"è¯·æ±‚URL: {full_url}")
        
        session = requests.Session()
        session.headers.update({
            'User-Agent': 'PancreaticCancerTrialsFinder/1.0'
        })
        
        response = session.get(full_url, timeout=30)
        
        if logger:
            logger.info(f"å“åº”çŠ¶æ€ç : {response.status_code}")
        
        response.raise_for_status()
        
        data = response.json()
        total_count = data.get('totalCount', 0)
        
        if logger:
            logger.info(f"æŸ¥è¯¢æˆåŠŸï¼Œè¿”å› {total_count} ä¸ªç»“æœ")
        
        return data
        
    except requests.exceptions.RequestException as e:
        if logger:
            logger.error(f"APIè¯·æ±‚å¤±è´¥: {e}")
        raise
    except json.JSONDecodeError as e:
        if logger:
            logger.error(f"JSONè§£æå¤±è´¥: {e}")
        raise

def get_pancreatic_cancer_trials(search_keywords: str = None, first_post_date: str = None, days_back: int = 30, phases: List[str] = None, status: List[str] = None, location: str = None, logger=None) -> List[Dict[str, Any]]:
    """
    è·å–èƒ°è…ºç™Œç›¸å…³çš„æ´»è·ƒä¸´åºŠè¯•éªŒ
    
    Args:
        search_keywords: æœç´¢å…³é”®è¯ï¼Œé»˜è®¤ä¸ºèƒ°è…ºç™Œç›¸å…³æœ¯è¯­
        first_post_date: é¦–æ¬¡å‘å¸ƒæ—¥æœŸè¿‡æ»¤ (YYYY-MM-DDæ ¼å¼)
        days_back: å‘å‰æŸ¥æ‰¾çš„å¤©æ•°ï¼Œé»˜è®¤30å¤©
        phases: è¯•éªŒé˜¶æ®µåˆ—è¡¨ ['0', '1', '2', '3', '4']
        status: è¯•éªŒçŠ¶æ€åˆ—è¡¨ ['RECRUITING', 'NOT_YET_RECRUITING', 'ACTIVE_NOT_RECRUITING']
        location: åœ°ç†ä½ç½®è¿‡æ»¤ï¼Œå¦‚'china'
        
    Returns:
        ç¬¦åˆæ¡ä»¶çš„è¯•éªŒåˆ—è¡¨
    """
    # æ„å»ºæœç´¢æŸ¥è¯¢
    if search_keywords:
        query = search_keywords
    else:
        query = "pancreatic cancer"
    
    try:
        # æœç´¢è¯•éªŒ
        data = search_studies(query, phases=phases, status=status, first_post_date=first_post_date, location=location, logger=logger)
        
        if 'studies' not in data:
            if logger:
                logger.warning("APIå“åº”ä¸­æ²¡æœ‰æ‰¾åˆ°studieså­—æ®µ")
            return []
        
        studies = data['studies']
        if logger:
            logger.info(f"è·å–åˆ° {len(studies)} ä¸ªè¯•éªŒ")
        
        # è®¾ç½®æ—¥æœŸè¿‡æ»¤æ¡ä»¶
        if first_post_date:
            try:
                cutoff_date = datetime.strptime(first_post_date, '%Y-%m-%d')
                if logger:
                    logger.info(f"ä½¿ç”¨ç”¨æˆ·æŒ‡å®šçš„é¦–æ¬¡å‘å¸ƒæ—¥æœŸè¿‡æ»¤: {first_post_date}")
            except ValueError:
                if logger:
                    logger.warning(f"æ—¥æœŸæ ¼å¼é”™è¯¯ï¼Œä½¿ç”¨é»˜è®¤è®¾ç½®: {first_post_date}")
                cutoff_date = datetime.now() - timedelta(days=days_back)
        else:
            cutoff_date = datetime.now() - timedelta(days=days_back)
        
        filtered_studies = []
        
        for study in studies:
            try:
                # æ£€æŸ¥æœ€åæ›´æ–°æ—¥æœŸ
                last_update_str = study.get('protocolSection', {}).get('statusModule', {}).get('lastUpdatePostDate', '')
                if last_update_str:
                    last_update = datetime.fromisoformat(last_update_str.replace('Z', '+00:00'))
                    if last_update.replace(tzinfo=None) >= cutoff_date:
                        filtered_studies.append(study)
                        continue
                
                # æ£€æŸ¥é¦–æ¬¡æäº¤æ—¥æœŸ (studyFirstSubmitDate) - ä¼˜å…ˆä½¿ç”¨
                first_submit_str = study.get('protocolSection', {}).get('statusModule', {}).get('studyFirstSubmitDate', '')
                if first_submit_str:
                    first_submit = datetime.strptime(first_submit_str, '%Y-%m-%d')
                    if first_submit >= cutoff_date:
                        filtered_studies.append(study)
                        continue
                
                # å¤‡ç”¨ï¼šæ£€æŸ¥é¦–æ¬¡å‘å¸ƒæ—¥æœŸç»“æ„ (studyFirstPostDateStruct)
                first_post_struct = study.get('protocolSection', {}).get('statusModule', {}).get('studyFirstPostDateStruct', {})
                if first_post_struct and 'date' in first_post_struct:
                    first_post_str = first_post_struct['date']
                    try:
                        first_post = datetime.strptime(first_post_str, '%Y-%m-%d')
                        if first_post >= cutoff_date:
                            filtered_studies.append(study)
                    except ValueError:
                        first_post = datetime.fromisoformat(first_post_str.replace('Z', '+00:00'))
                        if first_post.replace(tzinfo=None) >= cutoff_date:
                            filtered_studies.append(study)
                        
            except Exception as e:
                if logger:
                    logger.warning(f"å¤„ç†è¯•éªŒæ—¥æœŸæ—¶å‡ºé”™: {e}")
                # å¦‚æœæ—¥æœŸè§£æå¤±è´¥ï¼Œä»ç„¶åŒ…å«è¯¥è¯•éªŒ
                filtered_studies.append(study)
        
        if logger:
            logger.info(f"æ—¥æœŸè¿‡æ»¤åå‰©ä½™ {len(filtered_studies)} ä¸ªè¯•éªŒ")
        
        return filtered_studies
            
    except Exception as e:
        if logger:
            logger.error(f"æœç´¢è¯•éªŒæ—¶å‘ç”Ÿé”™è¯¯: {e}")
        return []

def load_api_response():
    """åŠ è½½APIå“åº”æ•°æ®ï¼ˆä¿æŒå‘åå…¼å®¹ï¼‰"""
    try:
        with open('api_response.json', 'r', encoding='utf-8') as f:
            return json.load(f)
    except FileNotFoundError:
        print("æœªæ‰¾åˆ°api_response.jsonæ–‡ä»¶")
        return None

def format_study_to_markdown(study):
    """å°†å•ä¸ªç ”ç©¶æ ¼å¼åŒ–ä¸ºMarkdown"""
    protocol = study.get('protocolSection', {})
    identification = protocol.get('identificationModule', {})
    status = protocol.get('statusModule', {})
    design = protocol.get('designModule', {})
    conditions = protocol.get('conditionsModule', {})
    interventions = protocol.get('armsInterventionsModule', {})
    contacts = protocol.get('contactsLocationsModule', {})
    eligibility = protocol.get('eligibilityModule', {})
    
    # åŸºæœ¬ä¿¡æ¯
    nct_id = identification.get('nctId', 'N/A')
    title = identification.get('briefTitle', 'N/A')
    overall_status = status.get('overallStatus', 'N/A')
    
    # æ¡ä»¶
    condition_list = conditions.get('conditions', [])
    condition_str = ', '.join(condition_list) if condition_list else 'N/A'
    
    # å¹²é¢„æªæ–½
    intervention_list = interventions.get('interventions', [])
    intervention_names = []
    for intervention in intervention_list:
        name = intervention.get('name', '')
        if name:
            intervention_names.append(name)
    intervention_str = ', '.join(intervention_names) if intervention_names else 'N/A'
    
    # ç”³åŠæ–¹
    sponsor_module = protocol.get('sponsorCollaboratorsModule', {})
    lead_sponsor = sponsor_module.get('leadSponsor', {})
    sponsor_name = lead_sponsor.get('name', 'N/A')
    
    # åœ°ç‚¹
    locations = contacts.get('locations', [])
    location_names = []
    for location in locations[:3]:  # åªæ˜¾ç¤ºå‰3ä¸ªåœ°ç‚¹
        facility = location.get('facility', '')
        city = location.get('city', '')
        country = location.get('country', '')
        if facility or city:
            loc_str = f"{facility}, {city}, {country}" if facility else f"{city}, {country}"
            location_names.append(loc_str)
    location_str = '; '.join(location_names) if location_names else 'N/A'
    
    # å…¥ç»„æ ‡å‡†
    criteria = eligibility.get('eligibilityCriteria', 'N/A')
    if len(criteria) > 200:
        criteria = criteria[:200] + '...'
    
    # è”ç³»ä¿¡æ¯
    overall_officials = contacts.get('overallOfficials', [])
    contact_info = 'N/A'
    if overall_officials:
        official = overall_officials[0]
        name = official.get('name', '')
        affiliation = official.get('affiliation', '')
        if name:
            contact_info = f"{name}" + (f" ({affiliation})" if affiliation else "")
    
    # å¼€å§‹æ—¥æœŸ
    start_date = status.get('startDateStruct', {}).get('date', 'N/A')
    
    # é¦–æ¬¡æäº¤æ—¥æœŸ (ä¼˜å…ˆä½¿ç”¨studyFirstSubmitDate)
    first_submit_date = status.get('studyFirstSubmitDate', '')
    if not first_submit_date:
        # å¤‡ç”¨ï¼šä½¿ç”¨studyFirstPostDateStruct
        first_post_struct = status.get('studyFirstPostDateStruct', {})
        first_submit_date = first_post_struct.get('date', 'N/A')
    
    markdown = f"""
#### {title}

- **è¯•éªŒç¼–å·**: {nct_id}
- **çŠ¶æ€**: {overall_status}
- **é€‚åº”ç—‡**: {condition_str}
- **å¹²é¢„æªæ–½**: {intervention_str}
- **ç”³åŠæ–¹**: {sponsor_name}
- **ç ”ç©¶åœ°ç‚¹**: {location_str}
- **å¼€å§‹æ—¥æœŸ**: {start_date}
- **é¦–æ¬¡æäº¤**: {first_submit_date}
- **ä¸»è¦ç ”ç©¶è€…**: {contact_info}
- **å…¥ç»„æ ‡å‡†**: {criteria}
- **è¯¦ç»†ä¿¡æ¯**: https://clinicaltrials.gov/study/{nct_id}

---

"""
    return markdown

def generate_report(search_keywords: str = None, first_post_date: str = '2025-01-01', days_back: int = 30, phases: List[str] = None, status: List[str] = None, location: str = None, use_api: bool = True):
    """
    ç”ŸæˆæŠ¥å‘Š
    
    Args:
        search_keywords: æœç´¢å…³é”®è¯ï¼Œé»˜è®¤ä¸ºèƒ°è…ºç™Œç›¸å…³æœ¯è¯­
        first_post_date: é¦–æ¬¡å‘å¸ƒæ—¥æœŸè¿‡æ»¤ (YYYY-MM-DDæ ¼å¼)
        days_back: å‘å‰æŸ¥æ‰¾çš„å¤©æ•°ï¼Œé»˜è®¤30å¤©
        phases: è¯•éªŒé˜¶æ®µåˆ—è¡¨ ['0', '1', '2', '3', '4']
        status: è¯•éªŒçŠ¶æ€åˆ—è¡¨ ['RECRUITING', 'NOT_YET_RECRUITING', 'ACTIVE_NOT_RECRUITING']
        location: åœ°ç†ä½ç½®è¿‡æ»¤ï¼Œå¦‚'china'
        use_api: æ˜¯å¦ç›´æ¥è°ƒç”¨APIï¼Œé»˜è®¤Trueï¼›Falseæ—¶ä»api_response.jsonè¯»å–
    """
    # è®¾ç½®æ—¥å¿—
    logger = setup_logging()
    
    if use_api:
        # ç›´æ¥è°ƒç”¨APIè·å–æœ€æ–°æ•°æ®
        logger.info("ç›´æ¥è°ƒç”¨APIè·å–æœ€æ–°æ•°æ®")
        studies = get_pancreatic_cancer_trials(
            search_keywords=search_keywords,
            first_post_date=first_post_date,
            days_back=days_back,
            phases=phases,
            status=status,
            location=location,
            logger=logger
        )
        
        if not studies:
            logger.warning("æœªè·å–åˆ°ä»»ä½•è¯•éªŒæ•°æ®")
            print("âŒ æœªè·å–åˆ°ä»»ä½•è¯•éªŒæ•°æ®")
            return
        
        # æ„å»ºæ•°æ®ç»“æ„ä»¥å…¼å®¹åŸæœ‰é€»è¾‘
        data = {
            'studies': studies,
            'totalCount': len(studies)
        }
        total_count = len(studies)
        
        # ä¿å­˜APIå“åº”æ•°æ®åˆ°æ–‡ä»¶
        try:
            with open('api_response.json', 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            logger.info("APIå“åº”æ•°æ®å·²ä¿å­˜åˆ° api_response.json")
        except Exception as e:
            logger.warning(f"ä¿å­˜APIå“åº”æ•°æ®å¤±è´¥: {e}")
    else:
        # ä»æ–‡ä»¶è¯»å–æ•°æ®ï¼ˆå‘åå…¼å®¹ï¼‰
        logger.info("ä»api_response.jsonæ–‡ä»¶è¯»å–æ•°æ®")
        data = load_api_response()
        if not data:
            logger.error("æœªæ‰¾åˆ°api_response.jsonæ–‡ä»¶")
            print("âŒ æœªæ‰¾åˆ°api_response.jsonæ–‡ä»¶")
            return
        
        studies = data.get('studies', [])
        total_count = data.get('totalCount', 0)
    
    # ç”ŸæˆæŠ¥å‘Š
    current_date = datetime.now().strftime('%Y-%m-%d')
    
    # æ ¹æ®æœç´¢å…³é”®è¯ç”Ÿæˆæ–‡ä»¶å
    if search_keywords:
        # æ¸…ç†æœç´¢å…³é”®è¯ï¼Œç§»é™¤ç‰¹æ®Šå­—ç¬¦ï¼Œç”¨äºæ–‡ä»¶å
        clean_keywords = search_keywords.replace(' ', '_').replace('/', '_').replace('\\', '_').replace(':', '_').replace('*', '_').replace('?', '_').replace('"', '_').replace('<', '_').replace('>', '_').replace('|', '_')
        # é™åˆ¶æ–‡ä»¶åé•¿åº¦
        if len(clean_keywords) > 30:
            clean_keywords = clean_keywords[:30]
        filename = f"{current_date}_{clean_keywords}_ä¸´åºŠè¯•éªŒæŠ¥å‘Š.md"
        report_title = f"{search_keywords}ä¸´åºŠè¯•éªŒæŠ¥å‘Š"
    else:
        filename = f"{current_date}_èƒ°è…ºç™Œä¸´åºŠè¯•éªŒæŠ¥å‘Š.md"
        report_title = "èƒ°è…ºç™Œä¸´åºŠè¯•éªŒæŠ¥å‘Š"
    
    content = f"""# {report_title}

**ç”Ÿæˆæ—¥æœŸ**: {current_date}
**æ•°æ®æ¥æº**: ClinicalTrials.gov API v2
**æŸ¥è¯¢æ¡ä»¶**: {search_keywords if search_keywords else 'èƒ°è…ºç™Œ'}ç›¸å…³çš„æ´»è·ƒä¸´åºŠè¯•éªŒ
**æ€»è®¡è¯•éªŒæ•°**: {total_count}
**æœ¬æ¬¡æ˜¾ç¤º**: {len(studies)} ä¸ªè¯•éªŒ

---

## è¯•éªŒåˆ—è¡¨

"""
    
    # æŒ‰çŠ¶æ€åˆ†ç»„
    recruiting_studies = []
    active_studies = []
    other_studies = []
    
    for study in studies:
        status = study.get('protocolSection', {}).get('statusModule', {}).get('overallStatus', '')
        if 'RECRUITING' in status.upper():
            recruiting_studies.append(study)
        elif 'ACTIVE' in status.upper():
            active_studies.append(study)
        else:
            other_studies.append(study)
    
    # æ·»åŠ æ‹›å‹Ÿä¸­çš„è¯•éªŒ
    if recruiting_studies:
        content += f"### æ­£åœ¨æ‹›å‹Ÿ ({len(recruiting_studies)} ä¸ªè¯•éªŒ)\n\n"
        for study in recruiting_studies:
            content += format_study_to_markdown(study)
    
    # æ·»åŠ æ´»è·ƒä½†ä¸æ‹›å‹Ÿçš„è¯•éªŒ
    if active_studies:
        content += f"### æ´»è·ƒä½†ä¸æ‹›å‹Ÿ ({len(active_studies)} ä¸ªè¯•éªŒ)\n\n"
        for study in active_studies:
            content += format_study_to_markdown(study)
    
    # æ·»åŠ å…¶ä»–çŠ¶æ€çš„è¯•éªŒ
    if other_studies:
        content += f"### å…¶ä»–çŠ¶æ€ ({len(other_studies)} ä¸ªè¯•éªŒ)\n\n"
        for study in other_studies:
            content += format_study_to_markdown(study)
    
    # ä¿å­˜æ–‡ä»¶
    try:
        with open(filename, 'w', encoding='utf-8') as f:
            f.write(content)
        print(f"âœ… æŠ¥å‘Šå·²ç”Ÿæˆ: {filename}")
        print(f"ğŸ“Š æ€»è®¡ {total_count} ä¸ªè¯•éªŒï¼Œæœ¬æ¬¡å¤„ç† {len(studies)} ä¸ª")
        print(f"ğŸ“‹ æ‹›å‹Ÿä¸­: {len(recruiting_studies)} ä¸ª")
        print(f"ğŸ“‹ æ´»è·ƒä½†ä¸æ‹›å‹Ÿ: {len(active_studies)} ä¸ª")
        print(f"ğŸ“‹ å…¶ä»–çŠ¶æ€: {len(other_studies)} ä¸ª")
        
    except Exception as e:
        print(f"âŒ ä¿å­˜æ–‡ä»¶å¤±è´¥: {e}")

if __name__ == "__main__":
    # ä½¿ç”¨é»˜è®¤å‚æ•°ç”ŸæˆæŠ¥å‘Š
    # å¯ä»¥æ ¹æ®éœ€è¦ä¿®æ”¹è¿™äº›å‚æ•°
    generate_report(
        search_keywords="pancreatic cancer",  # æµ‹è¯•ä½¿ç”¨è‹±æ–‡å…³é”®è¯
        first_post_date='2025-01-01',  # è¿‡æ»¤2025å¹´1æœˆ1æ—¥ä¹‹åçš„è¯•éªŒ
        days_back=30,  # å‘å‰æŸ¥æ‰¾30å¤©
        phases=None,  # åŒ…å«æ‰€æœ‰é˜¶æ®µ
        status=None,  # åŒ…å«æ‰€æœ‰çŠ¶æ€
        location=None,  # ä¸é™åˆ¶åœ°ç†ä½ç½®
        use_api=True  # ç›´æ¥è°ƒç”¨APIè·å–æœ€æ–°æ•°æ®
    )